{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "424329d0",
   "metadata": {},
   "source": [
    "# 예측 후 후처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9eb4df",
   "metadata": {},
   "source": [
    "## post_process.py - 박스 후처리\n",
    "### postprocess_boxes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5a16091",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def postprocess_boxes(pred_bbox, original_image, input_size, \n",
    "                      score_threshold):\n",
    "\n",
    "    valid_scale = [0, np.inf]\n",
    "    pred_bbox = np.array(pred_bbox)\n",
    "\n",
    "    pred_xywh = pred_bbox[:, 0:4]\n",
    "    pred_conf = pred_bbox[:, 4]\n",
    "    pred_prob = pred_bbox[:, 5:]\n",
    "\n",
    "    # 1. (x, y, w, h) --> (xmin, ymin, xmax, ymax) \n",
    "    pred_coor = np.concatenate( \n",
    "        [pred_xywh[:, :2] - pred_xywh[:, 2:] * 0.5,\n",
    "         pred_xywh[:, :2] + pred_xywh[:, 2:] * 0.5], axis=-1)\n",
    "\n",
    "    # 2. (xmin, ymin, xmax, ymax) -> (xmin_org, ymin_org, xmax_org, ymax_org) \n",
    "    org_h, org_w = original_image.shape[:2]\n",
    "    resize_ratio = min(input_size/org_w, input_size/org_h)\n",
    "\n",
    "    dw = (input_size - resize_ratio * org_w) / 2 \n",
    "    dh = (input_size - resize_ratio * org_h) / 2 \n",
    "\n",
    "    pred_coor[:, 0::2] = 1.0 * (pred_coor[:, 0::2] - dw) / resize_ratio\n",
    "    pred_coor[:, 1::2] = 1.0 * (pred_coor[:, 1::2] - dh) / resize_ratio\n",
    "\n",
    "    # 3. 범위를 벗어나는 박스를 자름 \n",
    "    pred_coor = np.concatenate(\n",
    "        [np.maximum(pred_coor[:, :2], [0, 0]),\n",
    "         np.minimum(pred_coor[:, 2:], [org_w-1, org_h-1])],\n",
    "        axis=-1)\n",
    "    invalid_mask = np.logical_or(\n",
    "        (pred_coor[:, 0] > pred_coor[:, 2]),\n",
    "        (pred_coor[:, 1] > pred_coor[:, 3]))\n",
    "    pred_coor[invalid_mask] = 0 \n",
    "\n",
    "    # 4. 유효하지 않은 상자 무시 \n",
    "    bboxes_scale = np.sqrt(\n",
    "        np.multiply.reduce(\n",
    "            pred_coor[:, 2:4] - pred_coor[:, 0:2], axis=-1))\n",
    "    scale_mask = np.logical_and(\n",
    "        (valid_scale[0] < bboxes_scale),\n",
    "        (bboxes_scale < valid_scale[1]))\n",
    "\n",
    "    # 5. 낮은 스코어의 상자 무시 \n",
    "    classes = np.argmax(pred_prob, axis=-1)\n",
    "    scores = pred_conf * pred_prob[np.arange(len(pred_coor)), classes]\n",
    "    score_mask = scores > score_threshold\n",
    "    mask = np.logical_and(scale_mask, score_mask)\n",
    "    coors, scores, classes = pred_coor[mask], scores[mask], classes[mask]\n",
    "\n",
    "    return np.concatenate([coors, scores[:, np.newaxis], \n",
    "                           classes[:, np.newaxis]], axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13da1e72",
   "metadata": {},
   "source": [
    "### NMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897aac8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-22 16:41:35.333014: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-12-22 16:41:35.374218: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-12-22 16:41:36.484066: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from bbox_iou import bbox_iou\n",
    "\n",
    "def nms(bboxes, iou_threshold, sigma=0.3, method='nms'):\n",
    "    classes_in_img = list(set(bboxes[:, 5]))\n",
    "    best_bboxes = []\n",
    "\n",
    "    for cls in classes_in_img:\n",
    "        cls_mask = (bboxes[:, 5] == cls)\n",
    "        cls_bboxes = bboxes[cls_mask]\n",
    "\n",
    "        # 1. 경계 상자의 개수가 0보다 큰지 확인  \n",
    "        while len(cls_bboxes) > 0:\n",
    "            # 2. 가장 높은 점수를 갖는 경계 상자를 선택 \n",
    "            max_ind = np.argmax(cls_bboxes[:, 4])\n",
    "            best_bbox = cls_bboxes[max_ind]\n",
    "            best_bboxes.append(best_bbox)\n",
    "            cls_bboxes = np.concatenate(\n",
    "                [cls_bboxes[: max_ind], \n",
    "                 cls_bboxes[max_ind + 1:]])\n",
    "  \n",
    "            # 3. 경계 상자의 모든 iou를 계산하고 iou 값이 임계값보다 높은 경계 상자를 제거 \n",
    "            iou = bbox_iou(best_bbox[np.newaxis, :4], cls_bboxes[:, :4], method='iou', isTrain=False)\n",
    "            weight = np.ones((len(iou),), dtype=np.float32)\n",
    "\n",
    "            assert method in ['nms', 'soft-nms']\n",
    "\n",
    "            if method == 'nms':\n",
    "                iou_mask = iou > iou_threshold\n",
    "                weight[iou_mask] = 0.0 \n",
    "\n",
    "            if method == 'soft-nms':\n",
    "                weight = np.exp(-(1.0 * iou ** 2 / sigma))\n",
    "\n",
    "            cls_bboxes[:, 4] = cls_bboxes[:, 4] * weight\n",
    "            score_mask = cls_bboxes[:, 4] > 0. \n",
    "            cls_bboxes = cls_bboxes[score_mask]\n",
    "\n",
    "    return best_bboxes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925645ca",
   "metadata": {},
   "source": [
    "### 사각형 그리기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b20e884",
   "metadata": {},
   "outputs": [],
   "source": [
    "import colorsys\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def draw_bbox(image, bboxes, class_names,\n",
    "              show_label=True, show_confidence=True,\n",
    "              Text_colors=(0,0,0), rectangle_colors='', \n",
    "              tracking=False):\n",
    "    image_h, image_w, _ = image.shape\n",
    "    num_classes = len(class_names)\n",
    "\n",
    "    hsv_tuples = [(1.0 * x / num_classes, 1., 1.) for x in range(num_classes)]\n",
    "    colors = list(map(lambda x: colorsys.hsv_to_rgb(*x), hsv_tuples))\n",
    "    colors = list(map(lambda x: (int(x[0] * 255), int(x[1] * 255), int(x[2] * 255)), colors))\n",
    "\n",
    "    random.seed(0)\n",
    "    random.shuffle(colors)\n",
    "    random.seed(None)\n",
    "\n",
    "    for i, bbox in enumerate(bboxes):\n",
    "        coor = np.array(bbox[:4], dtype=np.int32)\n",
    "        score = bbox[4]\n",
    "        class_ind = int(bbox[5])\n",
    "        bbox_color = rectangle_colors if rectangle_colors != '' else colors[class_ind]\n",
    "        bbox_thick = int(0.6 * (image_h + image_w) / 1000)\n",
    "        if bbox_thick < 1: bbox_thick = 1 \n",
    "        fontScale = 0.75 * bbox_thick\n",
    "        x1, y1 = coor[0], coor[1]\n",
    "        x2, y2 = coor[2], coor[3]\n",
    "\n",
    "        # 경계상자 그리기 \n",
    "        cv2.rectangle(image, (x1, y1), (x2, y2), \n",
    "                      bbox_color, bbox_thick * 2)\n",
    "\n",
    "        if show_label:\n",
    "            score_str = \"\" \n",
    "            if show_confidence:\n",
    "                score_str = \" {:.2f}\".format(score)\n",
    "            if tracking: \n",
    "                score_str = \" \" + str(score)\n",
    "\n",
    "            try:\n",
    "                label = f\"{class_names[class_ind]}{score_str}\"\n",
    "            except KeyError:\n",
    "                print(\"클래스 라벨이 잘못되었습니다.\")\n",
    "\n",
    "            # 텍스트 크기 \n",
    "            (text_width, text_height), baseline = cv2.getTextSize(\n",
    "                label, cv2.FONT_HERSHEY_COMPLEX_SMALL,\n",
    "                fontScale, thickness=bbox_thick)\n",
    "            # 텍스트를 출력할 채워진 사각형 \n",
    "            cv2.rectangle(image, (x1, y1), \n",
    "                          (x1 + text_width,\n",
    "                           y1 - text_height - baseline),\n",
    "                          bbox_color, thickness=cv2.FILLED)\n",
    "            # 사각형 위에 텍스트 출력 \n",
    "            cv2.putText(image, label, (x1, y1 - 4), \n",
    "                        cv2.FONT_HERSHEY_COMPLEX_SMALL,\n",
    "                        fontScale, Text_colors, bbox_thick,\n",
    "                        lineType=cv2.LINE_AA)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db3bc7b",
   "metadata": {},
   "source": [
    "# 실시간 객체 탐지 테스트"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb0f26a",
   "metadata": {},
   "source": [
    "## detect_image() - 객체 탐지 후 바운딩박스 그리기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93e766c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "\n",
    "from image_process import resize_to_square\n",
    "from data import read_class_names\n",
    "from post_process import *\n",
    "from config import NUM_CLASS\n",
    "\n",
    "def detect_image(model, image_path, output_path,\n",
    "                 class_label_path,\n",
    "                 input_size=416, show=False,\n",
    "                 score_threshold=0.3, iou_threshold=0.45,\n",
    "                 rectangle_colors=''):\n",
    "\n",
    "    original_image = cv2.imread(image_path)\n",
    "    if original_image is None:\n",
    "        raise ValueError(f\"Image not found: {image_path}\")\n",
    "\n",
    "    class_names = read_class_names(class_label_path)\n",
    "\n",
    "    # 1️⃣ letterbox resize\n",
    "    image_data = resize_to_square(\n",
    "        np.copy(original_image),\n",
    "        target_size=input_size\n",
    "    )\n",
    "    image_data = image_data[np.newaxis, ...].astype(np.float32)\n",
    "\n",
    "    # 2️⃣ forward\n",
    "    pred_bbox = model(image_data, training=False)\n",
    "\n",
    "    # 3️⃣ flatten\n",
    "    pred_bbox = [\n",
    "        tf.reshape(p, (-1, 5 + NUM_CLASS))\n",
    "        for p in pred_bbox\n",
    "    ]\n",
    "    pred_bbox = tf.concat(pred_bbox, axis=0).numpy()\n",
    "    print(\"pred_bbox shape:\", pred_bbox.shape)\n",
    "    print(np.unique(pred_bbox[:, -1].astype(int)))\n",
    "    print(\"pred_bbox sample:\", pred_bbox[:5])\n",
    "\n",
    "    # 4️⃣ post-process\n",
    "    bboxes = postprocess_boxes(\n",
    "        pred_bbox,\n",
    "        original_image,\n",
    "        input_size,\n",
    "        score_threshold\n",
    "    )\n",
    "    print(\"after postprocess:\", len(bboxes))\n",
    "\n",
    "\n",
    "    if len(bboxes) == 0:\n",
    "        print(\"⚠️ No objects detected\")\n",
    "\n",
    "    bboxes = nms(bboxes, iou_threshold)\n",
    "    print(bboxes[:5])\n",
    "\n",
    "    # 5️⃣ draw\n",
    "    image = draw_bbox(\n",
    "        original_image,\n",
    "        bboxes,\n",
    "        class_names,\n",
    "        rectangle_colors=rectangle_colors\n",
    "    )\n",
    "\n",
    "    if output_path:\n",
    "        cv2.imwrite(output_path, image)\n",
    "\n",
    "    if show:\n",
    "        cv2.imshow(\"predicted image\", image)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "    return image\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6cb23fa",
   "metadata": {},
   "source": [
    "## 학습된 모델 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84df8dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1766389297.646790   48085 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21751 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090 Ti, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "from yolov3 import Create_YOLOv3\n",
    "from config import NUM_CLASS\n",
    "\n",
    "yolo = Create_YOLOv3(\n",
    "    num_class=NUM_CLASS,\n",
    "    input_shape=(416, 416, 3),\n",
    "    train_mode=False   # 반드시 False\n",
    ")\n",
    "\n",
    "yolo.load_weights(\"checkpoints/mnist_custom_best.weights.h5\")\n",
    "# weights = yolo.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776c26b1",
   "metadata": {},
   "source": [
    "## 객체 탐지하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee631c66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-22 16:41:39.741025: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:473] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred_bbox shape: (10647, 15)\n",
      "[0]\n",
      "pred_bbox sample: [[ 3.1304078   4.3585496  15.216962   15.615939    0.04006871  0.03514211\n",
      "   0.27306983  0.14180715  0.10966711  0.1566938   0.15996712  0.05626611\n",
      "   0.07805344  0.14546919  0.03759608]\n",
      " [ 3.5414913   4.0433016  19.699347   17.049362    0.0412945   0.07555261\n",
      "   0.33621508  0.16459239  0.14181462  0.19127585  0.22862221  0.14350712\n",
      "   0.13137875  0.09163492  0.08041906]\n",
      " [ 3.6070492   3.8605068  32.306435   30.86019     0.03892223  0.08543364\n",
      "   0.3843721   0.19670457  0.14383763  0.15239574  0.30364197  0.13295338\n",
      "   0.30511066  0.09308022  0.12543218]\n",
      " [11.191127    4.0778008  14.773755   15.92569     0.04225546  0.03658172\n",
      "   0.18007363  0.17268106  0.11307348  0.21968305  0.14273582  0.05624708\n",
      "   0.05385464  0.12528646  0.03609953]\n",
      " [11.768534    3.7196596  18.033245   15.619322    0.03993796  0.088209\n",
      "   0.24415372  0.18728782  0.16341476  0.25128922  0.19286479  0.14425051\n",
      "   0.0989953   0.09563424  0.07515527]]\n",
      "after postprocess: 68\n",
      "[array([357.52307129, 137.25718689, 399.10827637, 179.39549255,\n",
      "         0.98159146,   1.        ]), array([170.57519531, 329.14807129, 225.55041504, 385.03717041,\n",
      "         0.96818244,   1.        ]), array([ 14.65619278, 115.57962036,  94.89363098, 196.92071533,\n",
      "         0.9614023 ,   1.        ]), array([230.79179382, 175.60397339, 271.50646973, 215.90567017,\n",
      "         0.97163838,   2.        ]), array([143.5422821 , 135.19439697, 166.54710388, 158.55209351,\n",
      "         0.95964742,   2.        ])]\n"
     ]
    }
   ],
   "source": [
    "# yolo.set_weights(weights)\n",
    "detect_image(\n",
    "    model=yolo,\n",
    "    image_path=\"mnist_test_c.jpg\",\n",
    "    output_path=\"result.jpg\",\n",
    "    class_label_path=\"dataset/mnist.names\",\n",
    "    show=True,\n",
    "    score_threshold=0.65,\n",
    "    iou_threshold=0.3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00d30e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
