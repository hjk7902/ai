{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64759373",
   "metadata": {},
   "source": [
    "# ëª¨ë¸ ì •ì˜í•˜ê¸°"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361c5d7b",
   "metadata": {},
   "source": [
    "## yolo.py - YOLOv3ì˜ í•©ì„±ê³±ê³¼ Residual"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20444768",
   "metadata": {},
   "source": [
    "### ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5c4e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155b347a",
   "metadata": {},
   "source": [
    "### BatchNormalization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66820a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchNormalization(layers.BatchNormalization):\n",
    "    # \"ë™ê²° ìƒíƒœ(Frozen state)\"ì™€ \"ì¶”ë¡  ëª¨ë“œ(Inference mode)\"ëŠ” ë³„ê°œì˜ ê°œë…ì…ë‹ˆë‹¤. \n",
    "    # 'layer.trainable=False' ì´ë©´ ë ˆì´ì–´ë¥¼ ë™ê²°ì‹œí‚µë‹ˆë‹¤. ì´ê²ƒì€ í›ˆë ¨í•˜ëŠ” ë™ì•ˆ ë‚´ë¶€ ìƒíƒœ ì¦‰, ê°€ì¤‘ì¹˜ê°€ ë°”ë€Œì§€ ì•ŠìŠµë‹ˆë‹¤.\n",
    "    # ê·¸ëŸ°ë° layer.trainable=Falseì´ë©´ ì¶”ë¡  ëª¨ë“œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤. \n",
    "    # ë ˆì´ì–´ëŠ” ì¶”ë¡ ëª¨ë“œì—ì„œ í˜„ì¬ ë°°ì¹˜ì˜ í‰ê·  ë° ë¶„ì‚°ì„ ì‚¬ìš©í•˜ëŠ” ëŒ€ì‹  í˜„ì¬ ë°°ì¹˜ë¥¼ ì •ê·œí™”í•˜ê¸° ìœ„í•´ ì´ë™ í‰ê· ê³¼ ì´ë™ ë¶„ì‚°ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "    def call(self, x, training=False):\n",
    "        if not training:\n",
    "            training = tf.constant(False)\n",
    "        training = tf.logical_and(training, self.trainable)\n",
    "        return super().call(x, training)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67eff2b2",
   "metadata": {},
   "source": [
    "### convolutional()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11eb8453",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional(input_layer, filters, kernel_size,\n",
    "                  downsample=False, activate=True, bn=True):\n",
    "    if downsample:\n",
    "        input_layer = layers.ZeroPadding2D(((1, 0), (1, 0)))(input_layer)\n",
    "        padding = 'valid'\n",
    "        strides = 2\n",
    "    else:\n",
    "        strides = 1\n",
    "        padding = 'same'\n",
    "\n",
    "    kernel_init = tf.random_normal_initializer(stddev=0.01)\n",
    "    conv = layers.Conv2D(filters=filters, \n",
    "                         kernel_size=kernel_size,\n",
    "                         strides=strides, padding=padding, \n",
    "                         use_bias=not bn,\n",
    "                         kernel_initializer=kernel_init,\n",
    "                         kernel_regularizer=l2(0.0005)\n",
    "                        )(input_layer)\n",
    "    if bn:\n",
    "        conv = BatchNormalization()(conv)\n",
    "    if activate:\n",
    "        conv = layers.LeakyReLU(alpha=0.1)(conv)\n",
    "\n",
    "    return conv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a162e72",
   "metadata": {},
   "source": [
    "### ë ˆì§€ë“€ì–¼ ë¸”ë¡ - residual_block()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236046cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_block(input_layer, filter_num1, filter_num2):\n",
    "    short_cut = input_layer\n",
    "    conv = convolutional(input_layer, filters=filter_num1, kernel_size=(1,1))\n",
    "    conv = convolutional(conv       , filters=filter_num2, kernel_size=(3,3))\n",
    "    residual_output = short_cut + conv\n",
    "    return residual_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14da4f8",
   "metadata": {},
   "source": [
    "### ë‹¤í¬ë„· ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e441c85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def darknet53(input_data):\n",
    "    input_data = convolutional(input_data, 32, (3,3))\n",
    "    input_data = convolutional(input_data, 64, (3,3), downsample=True)\n",
    "\n",
    "    for i in range(1):\n",
    "        input_data = residual_block(input_data,  32, 64)\n",
    "\n",
    "    input_data = convolutional(input_data, 128, (3,3), downsample=True)\n",
    "\n",
    "    for i in range(2):\n",
    "        input_data = residual_block(input_data, 64, 128)\n",
    "\n",
    "    input_data = convolutional(input_data, 256, (3,3), downsample=True)\n",
    "\n",
    "    for i in range(8):\n",
    "        input_data = residual_block(input_data, 128, 256)\n",
    "\n",
    "    route_1 = input_data\n",
    "    input_data = convolutional(input_data, 512, (3,3), downsample=True)\n",
    "\n",
    "    for i in range(8):\n",
    "        input_data = residual_block(input_data, 256, 512)\n",
    "\n",
    "    route_2 = input_data\n",
    "    input_data = convolutional(input_data, 1024, (3,3), downsample=True)\n",
    "\n",
    "    for i in range(4):\n",
    "        input_data = residual_block(input_data, 512, 1024)\n",
    "\n",
    "    return route_1, route_2, input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59faf35",
   "metadata": {},
   "source": [
    "### upsample() - ì—…ìƒ˜í”Œë§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c848bc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Upsample(layers.Layer):\n",
    "    def __init__(self, method='nearest', **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.method = method\n",
    "\n",
    "    def call(self, x):\n",
    "        # x.shape[1], x.shape[2]ëŠ” KerasTensorì¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ë™ì  í‘œí˜„ ì‚¬ìš©\n",
    "        h = tf.shape(x)[1]\n",
    "        w = tf.shape(x)[2]\n",
    "        new_size = (h * 2, w * 2)\n",
    "        return tf.image.resize(x, new_size, method=self.method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f06c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample(input_layer):\n",
    "    # ì´ì „ í•¨ìˆ˜ëª…ì´ë‘ ì¶©ëŒì„ ë°©ì§€í•˜ê¸° ìœ„í•´ functional-level wrapperë¥¼ ì œê³µ\n",
    "    return Upsample()(input_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f165733",
   "metadata": {},
   "source": [
    "### YOLOv3 í•¨ìˆ˜ ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b47029",
   "metadata": {},
   "outputs": [],
   "source": [
    "def YOLOv3(input_layer, num_class):\n",
    "    route_1, route_2, conv = darknet53(input_layer)\n",
    "\n",
    "    conv = convolutional(conv, 512, (1, 1))\n",
    "    conv = convolutional(conv, 1024, (3, 3))\n",
    "    conv = convolutional(conv, 512, (1, 1))\n",
    "    conv = convolutional(conv, 1024, (3, 3))\n",
    "    conv = convolutional(conv, 512, (1, 1))\n",
    "    conv_lobj_branch = convolutional(conv, 1024, (3, 3))\n",
    "\n",
    "    conv_lbbox = convolutional(conv_lobj_branch,\n",
    "                               3 * (num_class + 5), (1, 1),\n",
    "                               activate=False, bn=False)\n",
    "\n",
    "    conv = convolutional(conv, 256, (1, 1))\n",
    "    conv = Upsample()(conv)\n",
    "\n",
    "    # ğŸ”¥ tf.concat â†’ Keras Concatenate\n",
    "    conv = layers.Concatenate(axis=-1)([conv, route_2])\n",
    "\n",
    "    conv = convolutional(conv, 256, (1, 1))\n",
    "    conv = convolutional(conv, 512, (3, 3))\n",
    "    conv = convolutional(conv, 256, (1, 1))\n",
    "    conv = convolutional(conv, 512, (3, 3))\n",
    "    conv = convolutional(conv, 256, (1, 1))\n",
    "    conv_mobj_branch = convolutional(conv, 512, (3, 3))\n",
    "\n",
    "    conv_mbbox = convolutional(conv_mobj_branch,\n",
    "                               3 * (num_class + 5), (1, 1),\n",
    "                               activate=False, bn=False)\n",
    "\n",
    "    conv = convolutional(conv, 128, (1, 1))\n",
    "    conv = Upsample()(conv)\n",
    "\n",
    "    # ğŸ”¥ tf.concat â†’ Keras Concatenate\n",
    "    conv = layers.Concatenate(axis=-1)([conv, route_1])\n",
    "\n",
    "    conv = convolutional(conv, 128, (1, 1))\n",
    "    conv = convolutional(conv, 256, (3, 3))\n",
    "    conv = convolutional(conv, 128, (1, 1))\n",
    "    conv = convolutional(conv, 256, (3, 3))\n",
    "    conv = convolutional(conv, 128, (1, 1))\n",
    "    conv_sobj_branch = convolutional(conv, 256, (3, 3))\n",
    "\n",
    "    conv_sbbox = convolutional(conv_sobj_branch,\n",
    "                               3 * (num_class + 5), (1, 1),\n",
    "                               activate=False, bn=False)\n",
    "\n",
    "    return [conv_sbbox, conv_mbbox, conv_lbbox]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121ccef6",
   "metadata": {},
   "source": [
    "### í•©ì„±ê³± ì‹ ê²½ë§ì˜ ì¶œë ¥ì„ ë””ì½”ë”© í•¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efab343d",
   "metadata": {},
   "outputs": [],
   "source": [
    "YOLO_STRIDES  = [8, 16, 32]\n",
    "YOLO_ANCHORS  = [[[10,  13], [16,   30], [33,   23]],\n",
    "                 [[30,  61], [62,   45], [59,  119]],\n",
    "                 [[116, 90], [156, 198], [373, 326]]]\n",
    "STRIDES = np.array(YOLO_STRIDES)\n",
    "ANCHORS = (np.array(YOLO_ANCHORS).T / STRIDES).T   # ê¸°ì¡´ ë°©ì‹ ìœ ì§€\n",
    "\n",
    "# í…ì„œ ìƒìˆ˜ë¡œë„ ì¤€ë¹„\n",
    "TF_STRIDES = tf.constant(STRIDES, dtype=tf.float32)\n",
    "TF_ANCHORS = tf.constant(ANCHORS, dtype=tf.float32)  # shape (3,3,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a227fb5",
   "metadata": {},
   "source": [
    "### DecodeLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8e3488",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecodeLayer(layers.Layer):\n",
    "    def __init__(self, num_class, i, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.num_class = num_class\n",
    "        self.i = i\n",
    "        self.anchors = TF_ANCHORS[self.i]   # (3, 2)\n",
    "        self.stride  = TF_STRIDES[self.i]   # scalar\n",
    "\n",
    "    def call(self, conv_output):\n",
    "        # conv_output: (B, H, W, 3*(5+num_class))\n",
    "        conv_shape = tf.shape(conv_output)\n",
    "        batch_size = conv_shape[0]\n",
    "        output_size = conv_shape[1]\n",
    "\n",
    "        conv_output = tf.reshape(\n",
    "            conv_output,\n",
    "            (batch_size, output_size, output_size, 3, self.num_class + 5)\n",
    "        )\n",
    "\n",
    "        conv_raw_dxdy = conv_output[..., 0:2]\n",
    "        conv_raw_dwdh = conv_output[..., 2:4]\n",
    "        conv_raw_dwdh = tf.clip_by_value(conv_raw_dwdh, -10.0, 10.0)\n",
    "        conv_raw_conf = conv_output[..., 4:5]\n",
    "        conv_raw_prob = conv_output[..., 5:]\n",
    "\n",
    "        # grid\n",
    "        y = tf.range(output_size, dtype=tf.int32)\n",
    "        y = tf.tile(y[:, tf.newaxis], [1, output_size])\n",
    "        x = tf.range(output_size, dtype=tf.int32)\n",
    "        x = tf.tile(x[tf.newaxis, :], [output_size, 1])\n",
    "\n",
    "        xy_grid = tf.stack([x, y], axis=-1)\n",
    "        xy_grid = tf.cast(xy_grid, tf.float32)\n",
    "        xy_grid = tf.reshape(xy_grid, (1, output_size, output_size, 1, 2))\n",
    "\n",
    "        # decode\n",
    "        pred_xy = (tf.sigmoid(conv_raw_dxdy) + xy_grid) * self.stride\n",
    "        pred_wh = tf.exp(conv_raw_dwdh) * tf.cast(self.anchors, tf.float32) * self.stride\n",
    "        pred_wh = tf.maximum(pred_wh, 1e-6)\n",
    "\n",
    "        pred_xywh = tf.concat([pred_xy, pred_wh], axis=-1)\n",
    "        pred_conf = tf.sigmoid(conv_raw_conf)\n",
    "        pred_prob = tf.sigmoid(conv_raw_prob)\n",
    "\n",
    "        output = tf.concat([pred_xywh, pred_conf, pred_prob], axis=-1)\n",
    "        output = tf.reshape(\n",
    "            output,\n",
    "            (batch_size, output_size, output_size, 3 * (self.num_class + 5))\n",
    "        )\n",
    "\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e59f568",
   "metadata": {},
   "source": [
    "### YOLOv3 ëª¨ë¸ ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f1cb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Create_YOLOv3(num_class, input_shape=(416,416,3), train_mode=False):\n",
    "    input_layer  = layers.Input(input_shape)\n",
    "\n",
    "    # raw conv outputs (3ê°œ)\n",
    "    conv_tensors = YOLOv3(input_layer, num_class)\n",
    "\n",
    "    outputs = []\n",
    "\n",
    "    if train_mode:\n",
    "        # training: conv + decodedë¥¼ ëª¨ë‘ ì¶œë ¥\n",
    "        for i, conv in enumerate(conv_tensors):\n",
    "            pred = DecodeLayer(num_class, i)(conv)\n",
    "            outputs.append(conv)   # raw conv\n",
    "            outputs.append(pred)   # decoded pred\n",
    "    else:\n",
    "        # inference: decodedë§Œ ì¶œë ¥\n",
    "        for i, conv in enumerate(conv_tensors):\n",
    "            pred = DecodeLayer(num_class, i)(conv)\n",
    "            outputs.append(pred)\n",
    "\n",
    "    return tf.keras.Model(inputs=input_layer, outputs=outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42f66d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASS = 10\n",
    "model = Create_YOLOv3(num_class=NUM_CLASS, input_shape=(416,416,3), train_mode=True)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61fcb80a",
   "metadata": {},
   "source": [
    "# ëª¨ë¸ í›ˆë ¨ ì •ì˜í•˜ê¸°"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8450609b",
   "metadata": {},
   "source": [
    "## ì´ë¯¸ì§€ ì „ì²˜ë¦¬í•˜ê¸°(image_process.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0b0b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "# ì´ë¯¸ì§€ë¥¼ ì •ì‚¬ê°í˜• í¬ê¸°ë¡œ ë³€í™˜, \n",
    "# ì±„ì›Œì§€ëŠ” í™”ì†Œ ê¸°ë³¸ê°’ì€ valueì†ì„±ì˜ ê°’ìœ¼ë¡œ ì„¤ì •í•¨\n",
    "def resize_to_square(image, target_size, gt_boxes=None, value=128.0):\n",
    "    ih, iw = target_size, target_size\n",
    "    h, w, _ = image.shape\n",
    "\n",
    "    scale = min(iw / w, ih / h)\n",
    "    nw, nh = int(scale * w), int(scale * h)\n",
    "    image_resized = cv2.resize(image, (nw, nh))\n",
    "\n",
    "    image_padded = np.full(shape=[ih, iw, 3], fill_value=value)\n",
    "    dw, dh = (iw - nw) // 2, (ih - nh) // 2\n",
    "    image_padded[dh:nh + dh, dw:nw + dw, :] = image_resized\n",
    "    image_padded = image_padded / 255.\n",
    "\n",
    "    if gt_boxes is None:\n",
    "        return image_padded\n",
    "    else:\n",
    "        gt_boxes[:, [0, 2]] = gt_boxes[:, [0, 2]] * scale + dw\n",
    "        gt_boxes[:, [1, 3]] = gt_boxes[:, [1, 3]] * scale + dh\n",
    "        return image_padded, gt_boxes\n",
    "    \n",
    "\n",
    "def random_horizontal_flip(image, bboxes, p=0.5):\n",
    "    if random.random() < p:\n",
    "        _, w, _ = image.shape\n",
    "        image = image[:, ::-1, :]\n",
    "        bboxes[:, [0, 2]] = w - bboxes[:, [2, 0]]\n",
    "\n",
    "    return image, bboxes\n",
    "\n",
    "# ìë¥´ê¸° \n",
    "def random_crop(image, bboxes, p=0.5):\n",
    "    if random.random() < p:\n",
    "        h, w, _ = image.shape\n",
    "        max_bbox = np.concatenate( \n",
    "            [np.min(bboxes[:, 0:2], axis=0), \n",
    "             np.max(bboxes[:, 2:4], axis=0)], axis=-1)\n",
    "\n",
    "        max_l_trans = max_bbox[0]\n",
    "        max_u_trans = max_bbox[1]\n",
    "        max_r_trans = w - max_bbox[2]\n",
    "        max_d_trans = h - max_bbox[3]\n",
    "\n",
    "        crop_xmin = max(0, int(max_bbox[0] - random.uniform(0, max_l_trans)))\n",
    "        crop_ymin = max(0, int(max_bbox[1] - random.uniform(0, max_u_trans)))\n",
    "        crop_xmax = max(w, int(max_bbox[2] + random.uniform(0, max_r_trans)))\n",
    "        crop_ymax = max(h, int(max_bbox[3] + random.uniform(0, max_d_trans)))\n",
    "\n",
    "        image = image[crop_ymin:crop_ymax, crop_xmin:crop_xmax]\n",
    "\n",
    "        bboxes[:, [0, 2]] = bboxes[:, [0, 2]] - crop_xmin\n",
    "        bboxes[:, [1, 3]] = bboxes[:, [1, 3]] - crop_ymin\n",
    "  \n",
    "    return image, bboxes\n",
    "\n",
    "  \n",
    "# ì´ë™ \n",
    "def random_translate(image, bboxes, p=0.5):\n",
    "    if random.random() < p:\n",
    "        h, w, _ = image.shape\n",
    "        max_bbox = np.concatenate( \n",
    "            [np.min(bboxes[:, 0:2], axis=0),\n",
    "             np.max(bboxes[:, 2:4], axis=0)], axis=-1)\n",
    "\n",
    "        max_l_trans = max_bbox[0]\n",
    "        max_u_trans = max_bbox[1]\n",
    "        max_r_trans = w - max_bbox[2]\n",
    "        max_d_trans = h - max_bbox[3]\n",
    "\n",
    "        tx = random.uniform(-(max_l_trans-1), (max_r_trans-1))\n",
    "        ty = random.uniform(-(max_u_trans-1), (max_d_trans-1))\n",
    "\n",
    "        M = np.array([[1, 0, tx], [0, 1, ty]])\n",
    "        image = cv2.warpAffine(image, M, (w, h))\n",
    "\n",
    "        bboxes[:, [0, 2]] = bboxes[:, [0, 2]] + tx\n",
    "        bboxes[:, [1, 3]] = bboxes[:, [1, 3]] + ty\n",
    "\n",
    "    return image, bboxes\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938d2db6",
   "metadata": {},
   "source": [
    "## IoU ê³„ì‚°í•˜ê¸°(bbox_iou.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651b1e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "def bbox_iou(boxes1, boxes2):\n",
    "    boxes1_area = boxes1[..., 2] * boxes1[..., 3]\n",
    "    boxes2_area = boxes2[..., 2] * boxes2[..., 3]\n",
    "\n",
    "    boxes1 = tf.concat([boxes1[..., :2] - boxes1[..., 2:] * 0.5, \n",
    "                        boxes1[..., :2] + boxes1[..., 2:] * 0.5],\n",
    "                       axis=-1)\n",
    "    boxes2 = tf.concat([boxes2[..., :2] - boxes2[..., 2:] * 0.5, \n",
    "                        boxes2[..., :2] + boxes2[..., 2:] * 0.5],\n",
    "                       axis=-1)\n",
    "\n",
    "    left_up = tf.maximum(boxes1[..., :2], boxes2[..., :2])\n",
    "    right_down = tf.minimum(boxes1[..., 2:], boxes2[..., 2:])\n",
    "\n",
    "    inter_section = tf.maximum(right_down - left_up, 0.0)\n",
    "    inter_area = inter_section[..., 0] * inter_section[..., 1]\n",
    "    union_area = boxes1_area + boxes2_area - inter_area\n",
    "\n",
    "    return 1.0 * inter_area / union_area\n",
    " \n",
    "# GIoU ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜ \n",
    "def bbox_giou(boxes1, boxes2):\n",
    "    boxes1 = tf.concat([boxes1[..., :2] - boxes1[..., 2:] * 0.5,\n",
    "                        boxes1[..., :2] + boxes1[..., 2:] * 0.5],\n",
    "                       axis=-1)\n",
    "    boxes2 = tf.concat([boxes2[..., :2] - boxes2[..., 2:] * 0.5,\n",
    "                        boxes2[..., :2] + boxes2[..., 2:] * 0.5],\n",
    "                       axis=-1)\n",
    "\n",
    "    boxes1 = tf.concat([tf.minimum(boxes1[...,:2], boxes1[...,2:]),\n",
    "                        tf.maximum(boxes1[...,:2], boxes1[...,2:])], \n",
    "                       axis=-1)\n",
    "    boxes2 = tf.concat([tf.minimum(boxes2[...,:2], boxes2[...,2:]),\n",
    "                        tf.maximum(boxes2[...,:2], boxes2[...,2:])],\n",
    "                       axis=-1)\n",
    "\n",
    "    boxes1_area = (boxes1[..., 2] - boxes1[..., 0]) * (boxes1[..., 3] - boxes1[..., 1])\n",
    "    boxes2_area = (boxes2[..., 2] - boxes2[..., 0]) * (boxes2[..., 3] - boxes2[..., 1])\n",
    "\n",
    "    left_up = tf.maximum(boxes1[..., :2], boxes2[..., :2])\n",
    "    right_down = tf.minimum(boxes1[..., 2:], boxes2[..., 2:])\n",
    "\n",
    "    inter_section = tf.maximum(right_down - left_up, 0.0)\n",
    "    inter_area = inter_section[..., 0] * inter_section[..., 1]\n",
    "    union_area = boxes1_area + boxes2_area - inter_area\n",
    "  \n",
    "    # ë‘ ê²½ê³„ ìƒìì˜ IoUë¥¼ ê³„ì‚° \n",
    "    iou = inter_area / union_area\n",
    "\n",
    "    # ì™¼ìª½ ìœ„ì™€ ì˜¤ë¥¸ìª½ ì•„ë˜ë¥¼ í¬í•¨í•˜ëŠ” ê°€ì¥ ì‘ì€ ì‚¬ê°í˜• ê³„ì‚° \n",
    "    enclose_left_up = tf.minimum(boxes1[..., :2], boxes2[..., :2])\n",
    "    enclose_right_down = tf.maximum(boxes1[..., 2:], boxes2[..., 2:])\n",
    "    enclose = tf.maximum(enclose_right_down - enclose_left_up, 0.0)\n",
    "  \n",
    "    # ê°€ì¥ ì‘ì€ C ìƒìì˜ ë©´ì  ê³„ì‚° \n",
    "    enclose_area = enclose[..., 0] * enclose[..., 1]\n",
    "  \n",
    "    # GIoU ê³µì‹ìœ¼ë¡œ GIoU ê³„ì‚° \n",
    "    giou = iou - 1.0 * (enclose_area - union_area) / (enclose_area + 1e-8)\n",
    "\n",
    "    return giou\n",
    " \n",
    "# CIoU ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜ \n",
    "def bbox_ciou(boxes1, boxes2):\n",
    "    boxes1_coor = tf.concat([boxes1[...,:2] - boxes1[...,2:] * 0.5, \n",
    "                             boxes1[...,:2] + boxes1[...,2:] * 0.5], \n",
    "                            axis=-1)\n",
    "    boxes2_coor = tf.concat([boxes2[...,:2] - boxes2[...,2:] * 0.5, \n",
    "                             boxes2[...,:2] + boxes2[...,2:] * 0.5], \n",
    "                            axis=-1)\n",
    "\n",
    "    left = tf.maximum(boxes1_coor[..., 0], boxes2_coor[..., 0])\n",
    "    up = tf.maximum(boxes1_coor[..., 1], boxes2_coor[..., 1])\n",
    "    right = tf.maximum(boxes1_coor[..., 2], boxes2_coor[..., 2])\n",
    "    down = tf.maximum(boxes1_coor[..., 3], boxes2_coor[..., 3])\n",
    "\n",
    "    c = (right - left) * (right - left) + (up - down) * (up - down)\n",
    "    iou = bbox_iou(boxes1, boxes2)\n",
    "\n",
    "    u = (boxes1[..., 0] - boxes2[..., 0]) * (boxes1[..., 0] - boxes2[..., 0]) + (boxes1[..., 1] - boxes2[..., 1]) * (boxes1[..., 1] - boxes2[..., 1])\n",
    "    d = u / c\n",
    "\n",
    "    ar_gt = boxes2[..., 2] / boxes2[..., 3]\n",
    "    ar_pred = boxes1[..., 2] / boxes1[..., 3]\n",
    "\n",
    "    ar_loss = 4 / (np.pi * np.pi) * (tf.atan(ar_gt) - tf.atan(ar_pred)) * (tf.atan(ar_gt) - tf.atan(ar_pred))\n",
    "    alpha = ar_loss / (1 - iou + ar_loss + 0.000001)\n",
    "    ciou_term = d + alpha * ar_loss\n",
    " \n",
    "    return iou - ciou_term"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0a2372",
   "metadata": {},
   "source": [
    "## ìŠ¤íŠ¸ë¼ì´ë“œì™€ ì•µì»¤ë°•ìŠ¤(config.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc780c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "YOLO_STRIDES  = [8, 16, 32]\n",
    "YOLO_ANCHORS  = [[[10,  13], [16,   30], [33,   23]],\n",
    "                 [[30,  61], [62,   45], [59,  119]],\n",
    "                 [[116, 90], [156, 198], [373, 326]]]\n",
    "\n",
    "STRIDES       = np.array(YOLO_STRIDES)\n",
    "ANCHORS       = (np.array(YOLO_ANCHORS).T/STRIDES).T\n",
    "\n",
    "NUM_CLASS     = 10 # COCO ë°ì´í„°ì´ë©´ 80, MNIST ë°ì´í„°ì´ë©´ 10 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f884d2",
   "metadata": {},
   "source": [
    "## ë°ì´í„° ìƒì„±ê¸°(data.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11797be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "from config import *\n",
    "from image_process import *\n",
    "from bbox_iou import *\n",
    "\n",
    "\n",
    "# íŒŒì¼ì—ì„œ í´ë˜ìŠ¤ ë¼ë²¨ì„ ì½ì–´ ë”•ì…”ë„ˆë¦¬ë¡œ ë§Œë“¤ì–´ ë°˜í™˜\n",
    "def read_class_names(class_label_path):\n",
    "    names = {}\n",
    "    with open(class_label_path, 'r') as data:\n",
    "        for ID, name in enumerate(data):\n",
    "            names[ID] = name.strip('\\n')\n",
    "    return names\n",
    "\n",
    "\n",
    "class DataGenerator(object):\n",
    "    def __init__(self,\n",
    "                 data_path,\n",
    "                 annot_path,\n",
    "                 class_label_path,\n",
    "                 load_images_to_ram=True,\n",
    "                 data_aug=True,\n",
    "                 input_size=416,\n",
    "                 anchor_per_scale=3,\n",
    "                 max_bbox_per_scale=100, \n",
    "                 batch_size=4,\n",
    "                 strides=STRIDES, \n",
    "                 anchors=ANCHORS):\n",
    "        self.input_size = input_size\n",
    "        self.annot_path = annot_path\n",
    "        self.batch_size = batch_size\n",
    "        self.data_aug = data_aug\n",
    "        self.strides = strides\n",
    "        self.classes = read_class_names(class_label_path)\n",
    "        self.num_classes = len(self.classes)\n",
    "        self.anchors = anchors\n",
    "        self.anchor_per_scale = anchor_per_scale\n",
    "        self.max_bbox_per_scale = max_bbox_per_scale\n",
    "        self.load_images_to_ram = load_images_to_ram\n",
    "        self.annotations = self.load_annotations(annot_path)\n",
    "        self.num_samples = len(self.annotations)\n",
    "        self.num_batchs = int(np.ceil(self.num_samples / self.batch_size)) \n",
    "        self.batch_count = 0 \n",
    "        self.output_sizes = input_size // strides\n",
    "\n",
    "    # ì•„ë…¸í…Œì´ì…˜ ê²½ë¡œì—ì„œ ë°ì´í„°íŒŒì¼ì„ ì½ì–´ì˜´ \n",
    "    def load_annotations(self, annot_path):\n",
    "        # C:\\mnist_test\\000009.jpg \n",
    "        # 156,153,178,175,9 278,294,300,316,0 \n",
    "        annotations = []\n",
    "\n",
    "        with open(self.annot_path, 'r') as f:\n",
    "            # íŒŒì¼ì—ì„œ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì™€ ë¼ì¸ë³„ë¡œ ìë¦„ \n",
    "            data = f.read().splitlines()\n",
    "            # ê³µë°±ìœ¼ë¡œ ì˜ë¼ ë§¨ ì•ì˜ íŒŒì¼ê²½ë¡œì œì™¸í•˜ê³   \n",
    "            # ê¸¸ì´ê°€0ì´ ì•„ë‹Œ í–‰ë“¤ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë§Œë“¤ì–´ ë†“ìŒ \n",
    "            # íŒŒì¼ëª…ë§Œ ìˆëŠ” í–‰ ì œê±° \n",
    "            # (ê°ì²´ê°€ ì—†ëŠ” ì´ë¯¸ì§€ì˜ ì–´ë…¸í…Œì´ì…˜ ë°ì´í„°ì„) \n",
    "            lines = [line.strip() for line in data if len(line.strip().split()[1:]) != 0]\n",
    "        # ëœë¤í•˜ê²Œ ì„ìŒ \n",
    "        np.random.shuffle(lines)\n",
    "\n",
    "        for line in lines:\n",
    "            # ê³µë°±ìœ¼ë¡œ ë‚˜ëˆ” \n",
    "            # ì˜ˆ: line=['C:\\mnist_test\\000009.jpg', \n",
    "            # 156,153,178,175,9', '278,294,300,316,0'] \n",
    "            annotation = line.split()\n",
    "            image_path, index = \"\", 1\n",
    "            for i, one_line in enumerate(annotation):\n",
    "                if not one_line.replace(\",\",\"\").isnumeric():\n",
    "                    if image_path != \"\": \n",
    "                        image_path += \" \"\n",
    "                    image_path += one_line\n",
    "                else:\n",
    "                    index = i\n",
    "                    break\n",
    "\n",
    "            # ì–´ë…¸í…Œì´ì…˜ ì´ë¯¸ì§€íŒŒì¼ì´ ì—†ìœ¼ë©´ ì˜ˆì™¸ ë°œìƒì‹œí‚´ \n",
    "            if not os.path.exists(image_path):\n",
    "                raise KeyError(f\"{image_path} íŒŒì¼ì´ ì—†ìŒ\")\n",
    "\n",
    "            # ë¨ ì‚¬ìš©í•˜ë©´ ì´ë¯¸ì§€ë¥¼ ë©”ëª¨ë¦¬ì— ì €ì¥ í›„ ì‚¬ìš© \n",
    "            # ë¨ ì‚¬ìš©í•˜ì§€ ì•Šìœ¼ë©´ \n",
    "            #    __next__ì—ì„œ parse_annotationì„ ì‹¤í–‰, \n",
    "            #    parse_annotationì—ì„œ ì´ë¯¸ì§€ê°€ ë¡œë“œë¨ \n",
    "            if self.load_images_to_ram:\n",
    "                image = cv2.imread(image_path)\n",
    "            else:\n",
    "                image = '' \n",
    "\n",
    "            # [['C:\\mnist_test\\000009.jpg', \n",
    "            # [156,153,178,175,9', '278,294,300,316,0'], ''], ... ] \n",
    "            annotations.append([image_path, annotation[index:], image])\n",
    "\n",
    "        return annotations\n",
    "\n",
    "    # ì•„ë…¸í…Œì´ì…˜ ë°ì´í„° íŒŒì‹± \n",
    "    def parse_annotation(self, annotation, mAP='False'):\n",
    "        if self.load_images_to_ram:\n",
    "            image_path = annotation[0]\n",
    "            image = annotation[2]\n",
    "        else:\n",
    "            image_path = annotation[0]\n",
    "            image = cv2.imread(image_path) # ì´ë¯¸ì§€ë¥¼ ë¶ˆëŸ¬ì˜´ \n",
    "\n",
    "        #  [[156,153,178,175,9], [278,294,300,316,0]] \n",
    "        bboxes = np.array([list(map(int, box.split(','))) for box in annotation[1]])\n",
    "\n",
    "        # ì´ë¯¸ì§€ ì¦ê°• - ìˆ«ì, ë¬¸ìëŠ” ì¢Œ/ìš° ë°˜ì „ì´ í•„ìš” ì—†ìŒ \n",
    "        # ì´ë¯¸ì§€ë¥¼ ë³€í™˜í•˜ë©´ ê²½ê³„ ìƒìë„ ê°™ì´ ë°”ê¿”ì¤˜ì•¼ í•¨ \n",
    "        if self.data_aug:\n",
    "            # ì¢Œ/ìš° ë°˜ì „(ìƒëµ) \n",
    "#             image, bboxes = random_horizontal_flip(np.copy(image), np.copy(bboxes)) \n",
    "            # ìë¥´ê¸° \n",
    "            image, bboxes = random_crop(np.copy(image),\n",
    "                                        np.copy(bboxes))  \n",
    "            # ì´ë™ \n",
    "            image, bboxes = random_translate(np.copy(image),\n",
    "                                             np.copy(bboxes))\n",
    "\n",
    "        # mAP=Trueì´ë©´ image, bboxë¥¼ ë°˜í™˜\n",
    "        if mAP==True:\n",
    "            return image, bboxes\n",
    "        \n",
    "        image, bboxes = resize_to_square(np.copy(image), self.input_size, np.copy(bboxes))\n",
    "\n",
    "        return image, bboxes\n",
    " \n",
    "    # ìƒì ì „ì²˜ë¦¬ \n",
    "    def preprocess_true_boxes(self, bboxes):\n",
    "        # ìŠ¤íŠ¸ë¼ì´ë“œì˜ ìˆ˜ ë§Œí¼ ì¶œë ¥ ë ˆë²¨ì´ ë§Œë“¤ì–´ì§ \n",
    "        OUTPUT_LEVELS = len(self.strides)\n",
    "\n",
    "        # output_size = 416/[8, 16, 32] = [52, 26, 13] -> N\n",
    "        # anchor_per_scale = 3, num_classes = 10(MNISTì¼ ê²½ìš°)\n",
    "        # ì¶œë ¥ ë ˆë²¨ ìˆ˜ ë§Œí¼ (N,N,3,15) ëª¨ì–‘ì˜ ë¼ë²¨ ë°°ì—´ ì´ˆê¸°í™”\n",
    "        label = [np.zeros((self.output_sizes[i],\n",
    "                           self.output_sizes[i],\n",
    "                           self.anchor_per_scale,\n",
    "                           5 + self.num_classes))\n",
    "                 for i in range(OUTPUT_LEVELS)]\n",
    "        # max_bbox_per_scale = 100 \n",
    "        # ì¶œë ¥ ë ˆë²¨ ìˆ˜ ë§Œí¼ (100,4) ëª¨ì–‘ ê²½ê³„ìƒì ë°°ì—´ ì´ˆê¸°í™” \n",
    "        bboxes_xywh = [np.zeros((self.max_bbox_per_scale, 4))\n",
    "                       for _ in range(OUTPUT_LEVELS)]\n",
    "        # ì¶œë ¥ ë ˆë²¨ ìˆ˜ ë§Œí¼ ìƒì ìˆ˜ ë°°ì—´ ì´ˆê¸°í™” \n",
    "        bbox_count = np.zeros((OUTPUT_LEVELS,))\n",
    "\n",
    "        # ëª¨ë“  ìƒì ìˆ˜ ë§Œí¼ ì‹¤í–‰ \n",
    "        for bbox in bboxes:\n",
    "            # ìƒì ì¢Œí‘œ \n",
    "            bbox_coor = bbox[:4]\n",
    "            # ìƒì í´ë˜ìŠ¤ ë¼ë²¨ \n",
    "            bbox_class_ind = bbox[4]\n",
    "            # ìƒìì˜ í´ë˜ìŠ¤ ë¼ë²¨ ì›-í•« ì¸ì½”ë”©\n",
    "            onehot = np.zeros(self.num_classes, dtype=np.float64) \n",
    "            onehot[bbox_class_ind] = 1.0\n",
    "\n",
    "            # ì›-í•« ë¼ë²¨ í‰í™œí™”(Label Smoothing) \n",
    "            # ë ˆì´ë¸” ì •ê·œí™”ë¼ê³  ë¶€ë¥´ê¸°ë„ í•¨ \n",
    "            # ì†ì‹¤í•¨ìˆ˜ê°€ cross entropyì´ê³ ,\n",
    "            # í™œì„±í™” í•¨ìˆ˜ë¥¼ softmaxë¥¼ ì‚¬ìš©í•  ë•Œ ì ìš© \n",
    "            # ê°€ì¥ í° ë²¡í„°ê°€ ë‚˜ë¨¸ì§€ ë²¡í„°ë³´ë‹¤ ì»¤ì§€ëŠ” ê²ƒì„ ì–µì œ \n",
    "            # ê³µì‹: y_ls = (1-alpha)*y_onehot + alpha/K \n",
    "            K = self.num_classes\n",
    "            alpha = 0.01 \n",
    "            smooth_onehot = (1-alpha)*onehot + alpha/K \n",
    "\n",
    "            # ìƒì ì¢Œí‘œë¥¼ ìƒì x,y,w,hë¡œ ë³€í™˜ í›„ í‘œì¤€í™” \n",
    "            bbox_xywh = np.concatenate(\n",
    "                [(bbox_coor[2:] + bbox_coor[:2]) * 0.5,\n",
    "                 bbox_coor[2:] - bbox_coor[:2]], axis=-1)\n",
    "            bbox_xywh_scaled = 1.0 * bbox_xywh[np.newaxis, :] / self.strides[:, np.newaxis] \n",
    "\n",
    "            iou = []\n",
    "            exist_positive = False \n",
    "            for i in range(OUTPUT_LEVELS):  # range(3): \n",
    "                # ì•µì»¤ë°•ìŠ¤ \n",
    "                anchors_xywh = np.zeros((self.anchor_per_scale, 4))\n",
    "                anchors_xywh[:, 0:2] = np.floor(\n",
    "                    bbox_xywh_scaled[i, 0:2]).astype(np.int32)+0.5\n",
    "                anchors_xywh[:, 2:4] = self.anchors[i]\n",
    "\n",
    "                # ì‹¤ì œ ë°•ìŠ¤ì™€ ì•µì»¤ë°•ìŠ¤ IoUê³„ì‚° \n",
    "                iou_scale = bbox_iou(\n",
    "                    bbox_xywh_scaled[i][np.newaxis, :],\n",
    "                    anchors_xywh)\n",
    "                iou.append(iou_scale)\n",
    "\n",
    "                # IoUê°€ 0.3 ì´ìƒì¸ ë°•ìŠ¤ë§Œ ì²˜ë¦¬í•¨ \n",
    "                iou_mask = iou_scale > 0.3 \n",
    "                if np.any(iou_mask):\n",
    "                    xi, yi = np.floor(\n",
    "                        bbox_xywh_scaled[i, 0:2]).astype(np.int32) \n",
    "\n",
    "                    label[i][yi, xi, iou_mask, :] = 0 \n",
    "                    label[i][yi, xi, iou_mask, 0:4] = bbox_xywh\n",
    "                    label[i][yi, xi, iou_mask, 4:5] = 1.0 \n",
    "                    label[i][yi, xi, iou_mask, 5:] = smooth_onehot\n",
    "\n",
    "                    bbox_ind = int(                        bbox_count[i]%self.max_bbox_per_scale)\n",
    "                    bboxes_xywh[i][bbox_ind, :4] = bbox_xywh\n",
    "                    bbox_count[i] += 1 \n",
    "                    exist_positive = True \n",
    "  \n",
    "            if not exist_positive:\n",
    "                bst_anc_idx = np.argmax(np.array(iou).reshape(-1),\n",
    "                                        axis=-1)\n",
    "                best_detect = int(bst_anc_idx / self.anchor_per_scale)\n",
    "                best_anchor = int(bst_anc_idx % self.anchor_per_scale)\n",
    "                xi, yi = np.floor(\n",
    "                    bbox_xywh_scaled[best_detect,\n",
    "                                     0:2]).astype(np.int32)\n",
    "\n",
    "                label[best_detect][yi, xi, best_anchor, :] = 0 \n",
    "                label[best_detect][yi, xi,\n",
    "                                   best_anchor, 0:4] = bbox_xywh \n",
    "                label[best_detect][yi, xi,\n",
    "                                   best_anchor, 4:5] = 1.0 \n",
    "                label[best_detect][yi, xi,\n",
    "                                   best_anchor, 5:] = smooth_onehot \n",
    "\n",
    "                bbox_ind = int(bbox_count[best_detect] % self.max_bbox_per_scale)\n",
    "                bboxes_xywh[best_detect][bbox_ind, :4] = bbox_xywh \n",
    "                bbox_count[best_detect] += 1 \n",
    "\n",
    "        label_sbbox, label_mbbox, label_lbbox = label\n",
    "        sbboxes, mbboxes, lbboxes = bboxes_xywh\n",
    "        output_boxes = label_sbbox, label_mbbox, label_lbbox, sbboxes, mbboxes, lbboxes\n",
    "        return output_boxes \n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_batchs\n",
    "  \n",
    "    def __iter__(self):\n",
    "        return self \n",
    " \n",
    "    # ë°°ì¹˜ í¬ê¸°ë§Œí¼ ì´ë¯¸ì§€ì™€ ë¼ë²¨ ë°•ìŠ¤ë¥¼ ë°˜í™˜ \n",
    "    def __next__(self):\n",
    "        with tf.device('/cpu:0'):\n",
    "            # ë°°ì¹˜ ì´ë¯¸ì§€ë¥¼ ê°–ëŠ” ë°°ì—´ \n",
    "            batch_image = np.zeros( \n",
    "                (self.batch_size,\n",
    "                 self.input_size,\n",
    "                 self.input_size,\n",
    "                 3), dtype=np.float32)\n",
    " \n",
    "            # ë°°ì¹˜ ë¼ë²¨(small, middle, large) ê²½ê³„ ìƒì \n",
    "            batch_label_sbbox = np.zeros(\n",
    "                (self.batch_size,\n",
    "                 self.output_sizes[0],\n",
    "                 self.output_sizes[0],\n",
    "                 self.anchor_per_scale,\n",
    "                 5 + self.num_classes), dtype=np.float32)\n",
    "            batch_label_mbbox = np.zeros( \n",
    "                (self.batch_size,\n",
    "                 self.output_sizes[1],\n",
    "                 self.output_sizes[1],\n",
    "                 self.anchor_per_scale,\n",
    "                 5 + self.num_classes), dtype=np.float32)\n",
    "            batch_label_lbbox = np.zeros( \n",
    "                (self.batch_size,\n",
    "                 self.output_sizes[2], \n",
    "                 self.output_sizes[2], \n",
    "                 self.anchor_per_scale,\n",
    "                 5 + self.num_classes), dtype=np.float32)\n",
    " \n",
    "            # ë°°ì¹˜ í¬ê¸°ë§Œí¼ ê²½ê³„ ìƒìë¥¼ ì €ì¥í•  ë³€ìˆ˜ \n",
    "            batch_sbboxes = np.zeros(\n",
    "                (self.batch_size,\n",
    "                 self.max_bbox_per_scale, 4),\n",
    "                dtype=np.float32)\n",
    "            batch_mbboxes = np.zeros(\n",
    "                (self.batch_size, \n",
    "                 self.max_bbox_per_scale, 4),\n",
    "                dtype=np.float32)\n",
    "            batch_lbboxes = np.zeros( \n",
    "                (self.batch_size,\n",
    "                 self.max_bbox_per_scale, 4),\n",
    "                dtype=np.float32)\n",
    "\n",
    "            exceptions = False \n",
    "            num = 0 \n",
    "            if self.batch_count < self.num_batchs:\n",
    "                # ë°°ì¹˜ í¬ê¸°ë§Œí¼ ì‹¤í–‰   \n",
    "                while num < self.batch_size:  \n",
    "                    index = self.batch_count * self.batch_size + num \n",
    "                    if index >= self.num_samples: \n",
    "                        index -= self.num_samples\n",
    "                    annotation = self.annotations[index]\n",
    "                    image, bboxes = self.parse_annotation( annotation) \n",
    "                    try:\n",
    "                        label_sbbox, label_mbbox, label_lbbox, sbboxes, mbboxes, lbboxes = self.preprocess_true_boxes(bboxes) \n",
    "                    except IndexError:\n",
    "                        exceptions = True \n",
    "                        print(\"IndexError,\", annotation[0])\n",
    "\n",
    "                    batch_image[num,:,:,:] = image \n",
    "                    batch_label_mbbox[num,:,:,:,:] = label_mbbox \n",
    "                    batch_label_lbbox[num,:,:,:,:] = label_lbbox \n",
    "                    batch_mbboxes[num,:,:] = mbboxes \n",
    "                    batch_lbboxes[num,:,:] = lbboxes \n",
    "                    batch_label_sbbox[num,:,:,:,:] = label_sbbox \n",
    "                    batch_sbboxes[num,:,:] = sbboxes \n",
    "                    num += 1 \n",
    "\n",
    "                if exceptions:\n",
    "                    print('\\n')\n",
    "                    raise Exception(\"ë°ì´í„°ì…‹ì— ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "                self.batch_count += 1 \n",
    "                batch_sm_target = batch_label_sbbox, batch_sbboxes \n",
    "                batch_md_target = batch_label_mbbox, batch_mbboxes \n",
    "                batch_lg_target = batch_label_lbbox, batch_lbboxes \n",
    "\n",
    "                target=(batch_sm_target,batch_md_target,batch_lg_target) \n",
    "                return batch_image, target\n",
    "            else:\n",
    "                self.batch_count = 0\n",
    "                np.random.shuffle(self.annotations)\n",
    "                raise StopIteration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cdcb424",
   "metadata": {},
   "source": [
    "## train.py - í›ˆë ¨ì„ ì •ì˜í•˜ê¸°\n",
    "### GPU ì‚¬ìš© ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93069a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(f'GPUs {gpus}')\n",
    "\n",
    "if len(gpus) > 0:\n",
    "    try: \n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    except RuntimeError: \n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed7c1fb",
   "metadata": {},
   "source": [
    "### ìƒìˆ˜ ì •ì˜ (config.pyì˜ ì¼ë¶€)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9092b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOGDIR = \"logs\" # í•™ìŠµë¡œê·¸ë¥¼ ì €ì¥í•  ë””ë ‰í† ë¦¬\n",
    "\n",
    "WARMUP_EPOCHS = 2\n",
    "EPOCHS = 100\n",
    "\n",
    "SAVE_BEST_ONLY        = True              # val lossê°€ ê°€ì¥ ì¢‹ì€ ëª¨ë¸ì„ ì €ì¥, True ê¶Œì¥\n",
    "SAVE_CHECKPOINT       = True              # Trueì´ë©´ í•™ìŠµ ì‹œ ëª¨ë“  ìœ íš¨í•œ ëª¨ë¸ì„ ì €ì¥í•¨, False ê¶Œì¥\n",
    "CHECKPOINTS_FOLDER    = \"checkpoints\"     # ëª¨ë¸ì´ ì €ì¥ë  ë””ë ‰í† ë¦¬\n",
    "MODEL_NAME            = \"mnist_custom\"    # ì €ì¥ë  ëª¨ë¸ì˜ ì´ë¦„\n",
    "MODEL_EXTENSION       = \".weights.h5\"     # ëª¨ë¸ ì €ì¥ í™•ì¥ì\n",
    "SCORE_THRESHOLD       = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38437b9",
   "metadata": {},
   "source": [
    "### í•™ìŠµ ë¡œê·¸ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e7fbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "\n",
    "if os.path.exists(LOGDIR): \n",
    "    shutil.rmtree(LOGDIR) # ë¡œê·¸ ë””ë ‰í† ë¦¬ê°€ ìˆìœ¼ë©´ ì‚­ì œ \n",
    "\n",
    "writer = tf.summary.create_file_writer(LOGDIR)\n",
    "validate_writer = tf.summary.create_file_writer(LOGDIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c145aee",
   "metadata": {},
   "source": [
    "### compute_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bd2bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(pred, conv, label, bboxes, \n",
    "                 i=0, iou_loss_thresh=0.45):\n",
    "    conv_shape  = tf.shape(conv)\n",
    "    batch_size  = conv_shape[0]\n",
    "    output_size = conv_shape[1]\n",
    "    input_size  = STRIDES[i] * output_size\n",
    "    input_size  = tf.cast(input_size, tf.float32)\n",
    "\n",
    "    conv = tf.reshape(\n",
    "        conv,\n",
    "        (batch_size, output_size, output_size, 3, 5 + NUM_CLASS)\n",
    "    )\n",
    "    # raw logits (sigmoid ì´ì „ ê°’)\n",
    "    conv_raw_conf = conv[:, :, :, :, 4:5]\n",
    "    conv_raw_prob = conv[:, :, :, :, 5:]\n",
    "    \n",
    "    pred = conv\n",
    "\n",
    "    pred_xywh = pred[..., 0:4]\n",
    "    pred_conf = tf.sigmoid(pred[..., 4:5])\n",
    "\n",
    "    label_xywh    = label[:, :, :, :, 0:4]\n",
    "    label_xywh = tf.concat(\n",
    "        [label_xywh[..., 0:2], tf.maximum(label_xywh[..., 2:4], 1e-6)],\n",
    "        axis=-1\n",
    "    )\n",
    "    respond_bbox  = label[:, :, :, :, 4:5]\n",
    "    label_prob    = label[:, :, :, :, 5:]\n",
    "\n",
    "    giou = tf.expand_dims(bbox_giou(pred_xywh, label_xywh), axis=-1)\n",
    "    giou = tf.where(tf.math.is_finite(giou), giou, tf.zeros_like(giou))\n",
    "\n",
    "    input_size = tf.cast(input_size, tf.float32)    \n",
    "\n",
    "    bbox_loss_scale = 2.0 - 1.0 * label_xywh[:, :, :, :, 2:3] * label_xywh[:, :, :, :, 3:4] / (input_size ** 2 + 1e-8)\n",
    "    giou_loss = respond_bbox * bbox_loss_scale * (1 - giou)\n",
    "\n",
    "    # bbox_iou \n",
    "    iou = bbox_iou(pred_xywh[:, :, :, :, np.newaxis, :],\n",
    "                   bboxes[:, np.newaxis, np.newaxis, np.newaxis, :, :]) \n",
    "\n",
    "    # ì‹¤ì œ ìƒìì—ì„œ ê°€ì¥ í° ì˜ˆì¸¡ê°’ì„ ê°–ëŠ” ìƒìë¡œ IoU ê°’ ì°¾ê¸° \n",
    "    max_iou = tf.expand_dims(tf.reduce_max(iou, axis=-1),\n",
    "                             axis=-1)\n",
    "\n",
    "    # ê°€ì¥ í° iouê°€ ì„ê³„ê°’ë³´ë‹¤ ì‘ìœ¼ë©´ ì˜ˆì¸¡ ìƒìì— ê°œì²´ê°€ í¬í•¨ë˜ì§€ ì•Šì€ ê²ƒìœ¼ë¡œ ê°„ì£¼ë˜ê³  ë°°ê²½ ìƒìë¡œ ì„¤ì • \n",
    "    respond_bgd = (1.0 - respond_bbox) * tf.cast( max_iou < iou_loss_thresh, tf.float32 )\n",
    "\n",
    "    conf_focal = tf.pow(respond_bbox - pred_conf, 2)\n",
    "\n",
    "    # confidenceì˜ ì†ì‹¤ ê³„ì‚°  \n",
    "    # ê·¸ë¦¬ë“œì— ê°ì²´ê°€ í¬í•¨ëœ ê²½ìš° 1, ê·¸ë ‡ì§€ ì•Šì„ê²½ìš° 0  \n",
    "    conf_loss = conf_focal * (\n",
    "        respond_bbox * tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "            labels=respond_bbox, logits=conv_raw_conf)\n",
    "        + \n",
    "        respond_bgd * tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "            labels=respond_bbox, logits=conv_raw_conf) \n",
    "    )\n",
    "\n",
    "    prob_loss = respond_bbox * tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "        labels=label_prob, logits=conv_raw_prob)\n",
    "\n",
    "    giou_loss = tf.reduce_mean(tf.reduce_sum(giou_loss, axis=[1,2,3,4])) \n",
    "    conf_loss = tf.reduce_mean(tf.reduce_sum(conf_loss, axis=[1,2,3,4])) \n",
    "    prob_loss = tf.reduce_mean(tf.reduce_sum(prob_loss, axis=[1,2,3,4])) \n",
    "\n",
    "    return giou_loss, conf_loss, prob_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14709249",
   "metadata": {},
   "source": [
    "### í•™ìŠµ ë‹¨ê³„ ì •ì˜í•˜ê¸° - train_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18d7b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model, image_data, target, lr_init=1e-4, lr_end=1e-6):\n",
    "    with tf.GradientTape() as tape:\n",
    "        pred_result = model(image_data, training=True)\n",
    "\n",
    "        giou_loss = conf_loss = prob_loss = 0.0\n",
    "\n",
    "        for i in range(3):\n",
    "            conv = pred_result[i * 2]       # raw conv\n",
    "            pred = pred_result[i * 2 + 1]   # decoded pred\n",
    "\n",
    "            loss_items = compute_loss(pred, conv, *target[i], i)\n",
    "\n",
    "            giou_loss += loss_items[0]\n",
    "            conf_loss += loss_items[1]\n",
    "            prob_loss += loss_items[2]\n",
    "\n",
    "        total_loss = giou_loss + conf_loss + prob_loss\n",
    "\n",
    "    gradients = tape.gradient(total_loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    # learning rate update (ë‹¹ì‹  ì½”ë“œ ê·¸ëŒ€ë¡œ)\n",
    "    global_steps.assign_add(1)\n",
    "    if global_steps < warmup_steps:\n",
    "        lr = global_steps / warmup_steps * lr_init\n",
    "    else:\n",
    "        lr = lr_end + 0.5 * (lr_init - lr_end) * (\n",
    "            1 + tf.cos((global_steps - warmup_steps) /\n",
    "                       (total_steps - warmup_steps) * np.pi)\n",
    "        )\n",
    "\n",
    "    optimizer.learning_rate.assign(lr)\n",
    "\n",
    "    return (\n",
    "        global_steps.numpy(),\n",
    "        optimizer.learning_rate.numpy(),\n",
    "        giou_loss.numpy(),\n",
    "        conf_loss.numpy(),\n",
    "        prob_loss.numpy(),\n",
    "        total_loss.numpy(),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d945f35",
   "metadata": {},
   "source": [
    "### ê²€ì¦ ë‹¨ê³„ ì •ì˜í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef05b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_step(model, image_data, target):\n",
    "    with tf.GradientTape() as tape:\n",
    "        pred_result = model(image_data, training=False)\n",
    "        giou_loss = conf_loss = prob_loss = 0 \n",
    "\n",
    "        grid = 3 \n",
    "        for i in range(grid):\n",
    "            conv, pred = pred_result[i*2], pred_result[i*2+1]\n",
    "            loss_items = compute_loss(pred, conv, *target[i], i)\n",
    "            giou_loss += loss_items[0]\n",
    "            conf_loss += loss_items[1]\n",
    "            prob_loss += loss_items[2]\n",
    "\n",
    "        total_loss = giou_loss + conf_loss + prob_loss\n",
    "\n",
    "    return giou_loss.numpy(), conf_loss.numpy(), prob_loss.numpy(), total_loss.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43104949",
   "metadata": {},
   "source": [
    "### ëª¨ë“ˆ ë¶ˆëŸ¬ì™€ í•™ìŠµ ëª¨ë¸ ë§Œë“¤ê¸°"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a40aa3",
   "metadata": {},
   "source": [
    "### ë°ì´í„° ìƒì„±ê¸° ë§Œë“¤ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcd721c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from config import *\n",
    "from data import DataGenerator \n",
    "\n",
    "trainset = DataGenerator(data_path=\"dataset/mnist_train\",\n",
    "                         annot_path=\"dataset/mnist_train.txt\",\n",
    "                         class_label_path=\"dataset/mnist.names\")\n",
    "testset = DataGenerator(data_path=\"dataset/mnist_test\", \n",
    "                        annot_path=\"dataset/mnist_test.txt\",\n",
    "                        class_label_path=\"dataset/mnist.names\")\n",
    "steps_per_epoch = len(trainset)\n",
    "global_steps = tf.Variable(1, trainable=False, dtype=tf.int64)\n",
    "warmup_steps = WARMUP_EPOCHS * steps_per_epoch\n",
    "total_steps = EPOCHS * steps_per_epoch\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36b06a2",
   "metadata": {},
   "source": [
    "# í•™ìŠµì‹œí‚¤ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a1ab4e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from config import *\n",
    "from bbox_iou import bbox_iou, bbox_giou\n",
    "from yolov3 import Create_YOLOv3\n",
    "from train import *\n",
    "\n",
    "yolo = Create_YOLOv3(num_class=NUM_CLASS, train_mode=True)\n",
    "\n",
    "best_val_loss = float(\"inf\")\n",
    "os.makedirs(CHECKPOINTS_FOLDER, exist_ok=True)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "\n",
    "    # =========================\n",
    "    # ğŸ”¹ Train\n",
    "    # =========================\n",
    "    for image_data, target in trainset:\n",
    "        results = train_step(yolo, image_data, target)\n",
    "        cur_step = results[0] % steps_per_epoch\n",
    "\n",
    "        print(\n",
    "            \"epoch:{:3d} step:{:5.0f}/{}, lr:{:.6f}, \"\n",
    "            \"giou_loss:{:7.2f}, conf_loss:{:7.2f}, \"\n",
    "            \"prob_loss:{:7.2f}, total_loss:{:7.2f}\".format(\n",
    "                epoch, cur_step, steps_per_epoch,\n",
    "                results[1], results[2], results[3],\n",
    "                results[4], results[5]\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # =========================\n",
    "    # ğŸ”¹ Validation\n",
    "    # =========================\n",
    "    if len(testset) == 0:\n",
    "        print(\"âš ï¸ No validation set. Saving last model.\")\n",
    "\n",
    "        last_path = os.path.join(\n",
    "            CHECKPOINTS_FOLDER,\n",
    "            f\"{MODEL_NAME}_epoch_{epoch:03d}{MODEL_EXTENSION}\"\n",
    "        )\n",
    "        yolo.save_weights(last_path)\n",
    "        continue\n",
    "\n",
    "    count = 0\n",
    "    giou_val = conf_val = prob_val = total_val = 0.0\n",
    "\n",
    "    for image_data, target in testset:\n",
    "        results = validate_step(yolo, image_data, target)\n",
    "        count += 1\n",
    "        giou_val += results[0]\n",
    "        conf_val += results[1]\n",
    "        prob_val += results[2]\n",
    "        total_val += results[3]\n",
    "\n",
    "    giou_val /= count\n",
    "    conf_val /= count\n",
    "    prob_val /= count\n",
    "    total_val /= count\n",
    "\n",
    "    # =========================\n",
    "    # ğŸ”¹ TensorBoard log\n",
    "    # =========================\n",
    "    with validate_writer.as_default():\n",
    "        tf.summary.scalar(\"validate_loss/total\", total_val, step=epoch)\n",
    "        tf.summary.scalar(\"validate_loss/giou\", giou_val, step=epoch)\n",
    "        tf.summary.scalar(\"validate_loss/conf\", conf_val, step=epoch)\n",
    "        tf.summary.scalar(\"validate_loss/prob\", prob_val, step=epoch)\n",
    "    validate_writer.flush()\n",
    "\n",
    "    print(\n",
    "        \"\\n[Epoch {:03d}] \"\n",
    "        \"giou:{:.2f}, conf:{:.2f}, prob:{:.2f}, total:{:.2f}\\n\".format(\n",
    "            epoch, giou_val, conf_val, prob_val, total_val\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # =========================\n",
    "    # ğŸ”¹ Epochë³„ ì²´í¬í¬ì¸íŠ¸ ì €ì¥\n",
    "    # =========================\n",
    "    if SAVE_CHECKPOINT:\n",
    "        epoch_path = os.path.join(\n",
    "            CHECKPOINTS_FOLDER,\n",
    "            f\"{MODEL_NAME}_epoch_{epoch:03d}_val_{total_val:.2f}{MODEL_EXTENSION}\"\n",
    "        )\n",
    "        yolo.save_weights(epoch_path)\n",
    "\n",
    "    # =========================\n",
    "    # ğŸ”¹ Best ëª¨ë¸ ì €ì¥\n",
    "    # =========================\n",
    "    if SAVE_BEST_ONLY and total_val < best_val_loss:\n",
    "        best_val_loss = total_val\n",
    "        best_path = os.path.join(\n",
    "            CHECKPOINTS_FOLDER,\n",
    "            f\"{MODEL_NAME}_best{MODEL_EXTENSION}\"\n",
    "        )\n",
    "        yolo.save_weights(best_path)\n",
    "\n",
    "        print(f\"âœ… Best model updated (val_loss={best_val_loss:.2f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424329d0",
   "metadata": {},
   "source": [
    "# ì˜ˆì¸¡ í›„ í›„ì²˜ë¦¬"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9eb4df",
   "metadata": {},
   "source": [
    "## post_process.py - ë°•ìŠ¤ í›„ì²˜ë¦¬\n",
    "### postprocess_boxes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a16091",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def postprocess_boxes(pred_bbox, original_image, input_size, \n",
    "                      score_threshold):\n",
    "\n",
    "    valid_scale = [0, np.inf]\n",
    "    pred_bbox = np.array(pred_bbox)\n",
    "\n",
    "    pred_xywh = pred_bbox[:, 0:4]\n",
    "    pred_conf = pred_bbox[:, 4]\n",
    "    pred_prob = pred_bbox[:, 5:]\n",
    "\n",
    "    # 1. (x, y, w, h) --> (xmin, ymin, xmax, ymax) \n",
    "    pred_coor = np.concatenate( \n",
    "        [pred_xywh[:, :2] - pred_xywh[:, 2:] * 0.5,\n",
    "         pred_xywh[:, :2] + pred_xywh[:, 2:] * 0.5], axis=-1)\n",
    "\n",
    "    # 2. (xmin, ymin, xmax, ymax) -> (xmin_org, ymin_org, xmax_org, ymax_org) \n",
    "    org_h, org_w = original_image.shape[:2]\n",
    "    resize_ratio = min(input_size/org_w, input_size/org_h)\n",
    "\n",
    "    dw = (input_size - resize_ratio * org_w) / 2 \n",
    "    dh = (input_size - resize_ratio * org_h) / 2 \n",
    "\n",
    "    pred_coor[:, 0::2] = 1.0 * (pred_coor[:, 0::2] - dw) / resize_ratio\n",
    "    pred_coor[:, 1::2] = 1.0 * (pred_coor[:, 1::2] - dh) / resize_ratio\n",
    "\n",
    "    # 3. ë²”ìœ„ë¥¼ ë²—ì–´ë‚˜ëŠ” ë°•ìŠ¤ë¥¼ ìë¦„ \n",
    "    pred_coor = np.concatenate(\n",
    "        [np.maximum(pred_coor[:, :2], [0, 0]),\n",
    "         np.minimum(pred_coor[:, 2:], [org_w-1, org_h-1])],\n",
    "        axis=-1)\n",
    "    invalid_mask = np.logical_or(\n",
    "        (pred_coor[:, 0] > pred_coor[:, 2]),\n",
    "        (pred_coor[:, 1] > pred_coor[:, 3]))\n",
    "    pred_coor[invalid_mask] = 0 \n",
    "\n",
    "    # 4. ìœ íš¨í•˜ì§€ ì•Šì€ ìƒì ë¬´ì‹œ \n",
    "    bboxes_scale = np.sqrt(\n",
    "        np.multiply.reduce(\n",
    "            pred_coor[:, 2:4] - pred_coor[:, 0:2], axis=-1))\n",
    "    scale_mask = np.logical_and(\n",
    "        (valid_scale[0] < bboxes_scale),\n",
    "        (bboxes_scale < valid_scale[1]))\n",
    "\n",
    "    # 5. ë‚®ì€ ìŠ¤ì½”ì–´ì˜ ìƒì ë¬´ì‹œ \n",
    "    classes = np.argmax(pred_prob, axis=-1)\n",
    "    scores = pred_conf * pred_prob[np.arange(len(pred_coor)), classes]\n",
    "    score_mask = scores > score_threshold\n",
    "    mask = np.logical_and(scale_mask, score_mask)\n",
    "    coors, scores, classes = pred_coor[mask], scores[mask], classes[mask]\n",
    "\n",
    "    return np.concatenate([coors, scores[:, np.newaxis], \n",
    "                           classes[:, np.newaxis]], axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08c81c7",
   "metadata": {},
   "source": [
    "### ìƒìë“¤ì˜ IoU ê³„ì‚°í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225723b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def bboxes_iou(boxes1, boxes2):\n",
    "    boxes1 = np.array(boxes1)\n",
    "    boxes2 = np.array(boxes2)\n",
    "\n",
    "    boxes1_area = (boxes1[..., 2] - boxes1[..., 0]) * (boxes1[..., 3] - boxes1[..., 1])\n",
    "    boxes2_area = (boxes2[..., 2] - boxes2[..., 0]) * (boxes2[..., 3] - boxes2[..., 1])\n",
    "\n",
    "    left_up = np.maximum(boxes1[..., :2], boxes2[..., :2])\n",
    "    right_down = np.minimum(boxes1[..., 2:], boxes2[..., 2:])\n",
    "\n",
    "    inter_section = np.maximum(right_down - left_up, 0.0)\n",
    "    inter_area = inter_section[..., 0] * inter_section[..., 1]\n",
    "    union_area = boxes1_area + boxes2_area - inter_area\n",
    "\n",
    "    ious = np.maximum(1.0 * inter_area / union_area, np.finfo(np.float32).eps)\n",
    "\n",
    "    return ious"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13da1e72",
   "metadata": {},
   "source": [
    "### NMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897aac8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def nms(bboxes, iou_threshold, sigma=0.3, method='nms'):\n",
    "    classes_in_img = list(set(bboxes[:, 5]))\n",
    "    best_bboxes = []\n",
    "\n",
    "    for cls in classes_in_img:\n",
    "        cls_mask = (bboxes[:, 5] == cls)\n",
    "        cls_bboxes = bboxes[cls_mask]\n",
    "\n",
    "        # 1. ê²½ê³„ ìƒìì˜ ê°œìˆ˜ê°€ 0ë³´ë‹¤ í°ì§€ í™•ì¸  \n",
    "        while len(cls_bboxes) > 0:\n",
    "            # 2. ê°€ì¥ ë†’ì€ ì ìˆ˜ë¥¼ ê°–ëŠ” ê²½ê³„ ìƒìë¥¼ ì„ íƒ \n",
    "            max_ind = np.argmax(cls_bboxes[:, 4])\n",
    "            best_bbox = cls_bboxes[max_ind]\n",
    "            best_bboxes.append(best_bbox)\n",
    "            cls_bboxes = np.concatenate(\n",
    "                [cls_bboxes[: max_ind], \n",
    "                 cls_bboxes[max_ind + 1:]])\n",
    "  \n",
    "            # 3. ê²½ê³„ ìƒìì˜ ëª¨ë“  iouë¥¼ ê³„ì‚°í•˜ê³  iou ê°’ì´ ì„ê³„ê°’ë³´ë‹¤ ë†’ì€ ê²½ê³„ ìƒìë¥¼ ì œê±° \n",
    "            iou = bboxes_iou(best_bbox[np.newaxis, :4],\n",
    "                             cls_bboxes[:, :4])\n",
    "            weight = np.ones((len(iou),), dtype=np.float32)\n",
    "\n",
    "            assert method in ['nms', 'soft-nms']\n",
    "\n",
    "            if method == 'nms':\n",
    "                iou_mask = iou > iou_threshold\n",
    "                weight[iou_mask] = 0.0 \n",
    "\n",
    "            if method == 'soft-nms':\n",
    "                weight = np.exp(-(1.0 * iou ** 2 / sigma))\n",
    "\n",
    "            cls_bboxes[:, 4] = cls_bboxes[:, 4] * weight\n",
    "            score_mask = cls_bboxes[:, 4] > 0. \n",
    "            cls_bboxes = cls_bboxes[score_mask]\n",
    "\n",
    "    return best_bboxes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925645ca",
   "metadata": {},
   "source": [
    "### ì‚¬ê°í˜• ê·¸ë¦¬ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b20e884",
   "metadata": {},
   "outputs": [],
   "source": [
    "import colorsys\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def draw_bbox(image, bboxes, class_names,\n",
    "              show_label=True, show_confidence=True,\n",
    "              Text_colors=(0,0,0), rectangle_colors='', \n",
    "              tracking=False):\n",
    "    image_h, image_w, _ = image.shape\n",
    "    num_class = len(class_names)\n",
    "\n",
    "    hsv_tuples = [(1.0 * x / num_classes, 1., 1.) for x in range(num_classes)]\n",
    "    colors = list(map(lambda x: colorsys.hsv_to_rgb(*x), hsv_tuples))\n",
    "    colors = list(map(lambda x: (int(x[0] * 255), int(x[1] * 255), int(x[2] * 255)), colors))\n",
    "\n",
    "    random.seed(0)\n",
    "    random.shuffle(colors)\n",
    "    random.seed(None)\n",
    "\n",
    "    for i, bbox in enumerate(bboxes):\n",
    "        coor = np.array(bbox[:4], dtype=np.int32)\n",
    "        score = bbox[4]\n",
    "        class_ind = int(bbox[5])\n",
    "        bbox_color = rectangle_colors if rectangle_colors != '' else colors[class_ind]\n",
    "        bbox_thick = int(0.6 * (image_h + image_w) / 1000)\n",
    "        if bbox_thick < 1: bbox_thick = 1 \n",
    "        fontScale = 0.75 * bbox_thick\n",
    "        x1, y1 = coor[0], coor[1]\n",
    "        x2, y2 = coor[2], coor[3]\n",
    "\n",
    "        # ê²½ê³„ìƒì ê·¸ë¦¬ê¸° \n",
    "        cv2.rectangle(image, (x1, y1), (x2, y2), \n",
    "                      bbox_color, bbox_thick * 2)\n",
    "\n",
    "        if show_label:\n",
    "            score_str = \"\" \n",
    "            if show_confidence:\n",
    "                score_str = \" {:.2f}\".format(score)\n",
    "            if tracking: \n",
    "                score_str = \" \" + str(score)\n",
    "\n",
    "            try:\n",
    "                label = f\"{_class_names[class_ind]}{score_str}\"\n",
    "            except KeyError:\n",
    "                print(\"í´ë˜ìŠ¤ ë¼ë²¨ì´ ì˜ëª»ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "            # í…ìŠ¤íŠ¸ í¬ê¸° \n",
    "            (text_width, text_height), baseline = cv2.getTextSize(\n",
    "                label, cv2.FONT_HERSHEY_COMPLEX_SMALL,\n",
    "                fontScale, thickness=bbox_thick)\n",
    "            # í…ìŠ¤íŠ¸ë¥¼ ì¶œë ¥í•  ì±„ì›Œì§„ ì‚¬ê°í˜• \n",
    "            cv2.rectangle(image, (x1, y1), \n",
    "                          (x1 + text_width,\n",
    "                           y1 - text_height - baseline),\n",
    "                          bbox_color, thickness=cv2.FILLED)\n",
    "            # ì‚¬ê°í˜• ìœ„ì— í…ìŠ¤íŠ¸ ì¶œë ¥ \n",
    "            cv2.putText(image, label, (x1, y1 - 4), \n",
    "                        cv2.FONT_HERSHEY_COMPLEX_SMALL,\n",
    "                        fontScale, Text_colors, bbox_thick,\n",
    "                        lineType=cv2.LINE_AA)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db3bc7b",
   "metadata": {},
   "source": [
    "# ì‹¤ì‹œê°„ ê°ì²´ íƒì§€ í…ŒìŠ¤íŠ¸"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb0f26a",
   "metadata": {},
   "source": [
    "## detect_image() - ê°ì²´ íƒì§€ í›„ ë°”ìš´ë”©ë°•ìŠ¤ ê·¸ë¦¬ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e766c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "\n",
    "from image_process import resize_to_square\n",
    "from data import read_class_names\n",
    "from post_process import *\n",
    "\n",
    "def detect_image(model, image_path, output_path,\n",
    "                 class_label_path,\n",
    "                 input_size=416, show=False,\n",
    "                 score_threshold=0.3, iou_threshold=0.45,\n",
    "                 rectangle_colors=''):\n",
    "\n",
    "    original_image = cv2.imread(image_path)\n",
    "    if original_image is None:\n",
    "        raise ValueError(f\"Image not found: {image_path}\")\n",
    "\n",
    "    class_names = read_class_names(class_label_path)\n",
    "\n",
    "    # 1ï¸âƒ£ letterbox resize\n",
    "    image_data = resize_to_square(\n",
    "        np.copy(original_image),\n",
    "        target_size=input_size\n",
    "    )\n",
    "    image_data = image_data[np.newaxis, ...].astype(np.float32)\n",
    "\n",
    "    # 2ï¸âƒ£ forward\n",
    "    pred_bbox = model(image_data, training=False)\n",
    "\n",
    "    # 3ï¸âƒ£ flatten\n",
    "    pred_bbox = [tf.reshape(x, (-1, tf.shape(x)[-1])) for x in pred_bbox]\n",
    "    pred_bbox = tf.concat(pred_bbox, axis=0).numpy()\n",
    "\n",
    "    # 4ï¸âƒ£ post-process\n",
    "    bboxes = postprocess_boxes(\n",
    "        pred_bbox,\n",
    "        original_image,\n",
    "        input_size,\n",
    "        score_threshold\n",
    "    )\n",
    "\n",
    "    if len(bboxes) == 0:\n",
    "        print(\"âš ï¸ No objects detected\")\n",
    "\n",
    "    bboxes = nms(bboxes, iou_threshold)\n",
    "\n",
    "    # 5ï¸âƒ£ draw\n",
    "    image = draw_bbox(\n",
    "        original_image,\n",
    "        bboxes,\n",
    "        class_names,\n",
    "        rectangle_colors=rectangle_colors\n",
    "    )\n",
    "\n",
    "    if output_path:\n",
    "        cv2.imwrite(output_path, image)\n",
    "\n",
    "    if show:\n",
    "        cv2.imshow(\"predicted image\", image)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "    return image\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6cb23fa",
   "metadata": {},
   "source": [
    "## í•™ìŠµëœ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84df8dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from yolov3 import Create_YOLOv3\n",
    "from config import NUM_CLASS\n",
    "\n",
    "yolo = Create_YOLOv3(\n",
    "    num_class=NUM_CLASS,\n",
    "    input_shape=(416, 416, 3),\n",
    "    train_mode=False   # ë°˜ë“œì‹œ False\n",
    ")\n",
    "\n",
    "yolo.load_weights(\"checkpoints/mnist_custom_best.weights.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776c26b1",
   "metadata": {},
   "source": [
    "## ê°ì²´ íƒì§€í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee631c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_image(\n",
    "    model=yolo,\n",
    "    image_path=\"mnist_test_c.jpg\",\n",
    "    output_path=\"result.jpg\",\n",
    "    class_label_path=\"dataset/mnist.names\",\n",
    "    show=True,\n",
    "    score_threshold=0.3,\n",
    "    iou_threshold=0.45\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70606f10",
   "metadata": {},
   "source": [
    "## Realtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654aa3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# from image_process import resize_to_square\n",
    "# from data import read_class_names\n",
    "# from post_process import *\n",
    "# from yolov3 import Create_YOLOv3\n",
    "\n",
    "yolo = Create_YOLOv3(num_class=10)\n",
    "yolo.load_weights(\"checkpoints/mnist_custom\")\n",
    "weights = yolo.get_weights()\n",
    "class_names = read_class_names(\"dataset/mnist.names\")\n",
    "\n",
    "cap = cv2.VideoCapture(1)\n",
    "if cap.isOpened():\n",
    "    while True:\n",
    "        yolo.set_weights(weights)\n",
    "        ret, image = cap.read()\n",
    "        if not ret:\n",
    "            print(\"í”„ë ˆì„ì„ ë°›ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.\")\n",
    "            break \n",
    "\n",
    "        # ë°ê¸°ë¥¼ 100ë§Œí¼ ë”í•¨ \n",
    "        dummy = np.full(image.shape, fill_value=100, \n",
    "                        dtype=np.uint8)\n",
    "        cv2.add(image, dummy, image)\n",
    "                \n",
    "        # ì½˜íŠ¸ë¼ìŠ¤íŠ¸ ê°•ì¡°í•¨ \n",
    "        image = cv2.normalize(image, None, 0, 255,\n",
    "                              cv2.NORM_MINMAX)\n",
    "\n",
    "        # ì´ë¯¸ì§€ë¥¼ ì •ì‚¬ê°í˜• ëª¨ì–‘ìœ¼ë¡œ ë§Œë“¬ \n",
    "        image_data = resize_to_square(np.copy(image), 416)\n",
    "        image_data = image_data[np.newaxis,\n",
    "                                ...].astype(np.float32)\n",
    "\n",
    "        # ìƒì ì˜ˆì¸¡ \n",
    "        pred_box = yolo.predict(image_data)\n",
    "        pred_box = [tf.reshape(x, (-1, tf.shape(x)[-1])) \n",
    "                    for x in pred_box]\n",
    "        pred_box = tf.concat(pred_box, axis=0)\n",
    "\n",
    "        # ìƒì í›„ì²˜ë¦¬ \n",
    "        bboxes = postprocess_boxes(pred_box, image, 416, 0.3)\n",
    "\n",
    "        # NMSì— ì˜í•´ í•´ë‹¹ ì˜ì—­ì—ì„œ ìƒì í•˜ë‚˜ë§Œ ë‚¨ê¹€ \n",
    "        bboxes = nms(bboxes, 0.45, method=\"nms\")\n",
    "\n",
    "        # ìƒìë¥¼ ê·¸ë¦¼ \n",
    "        image = draw_bbox(image, bboxes, class_names)\n",
    "\n",
    "        cv2.imshow(\"Image\", image)\n",
    "        if cv2.waitKey(1) & 0xFF == 27:\n",
    "            break\n",
    "else:\n",
    "    print('ì—°ê²°ëœ ì¹´ë©”ë¼ê°€ ì—†ìŠµë‹ˆë‹¤.')\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf296f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# yolo.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6b9a41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
